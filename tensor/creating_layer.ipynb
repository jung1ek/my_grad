{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6784951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creatin new Linear layer for batch with numpy dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b670259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensor import Tensor\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6b1d1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_to_tensor = np.vectorize(lambda x: Tensor(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ee75663",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Linear:\n",
    "\n",
    "    def __init__(self,d_in,d_out):\n",
    "        k = 1/d_in\n",
    "        bound = np.sqrt(k)\n",
    "        w = np.random.uniform(-bound,bound,size=(d_in,d_out))\n",
    "        b = np.ones(d_out)\n",
    "        self.W = np_to_tensor(w)\n",
    "        self.B = np_to_tensor(b)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = np_to_tensor(x)\n",
    "        return np.matmul(x,self.W)+self.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7016f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = Linear(786,786)\n",
    "a = np.random.randn(786)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c99b5ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.110000000000582\n"
     ]
    }
   ],
   "source": [
    "s = time.monotonic()\n",
    "l.forward(a)\n",
    "e = time.monotonic()\n",
    "print(e-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7733abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(786)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71ebd544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01599999999962165\n"
     ]
    }
   ],
   "source": [
    "s= time.monotonic()\n",
    "np.dot(np.random.randn(786,786),x.T)\n",
    "e = time.monotonic()\n",
    "print(e-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08630831",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn import Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b2ad306",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = Linear(786,786)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b5429bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Tensor(1.8436403100836443, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.6149252445087914, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8181925899974161, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.18509343418726487, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.15572283030662215, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7024487988985127, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.849779316271736, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2636767612869684, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0825738648195602, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0637678123595635, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0055946248190661, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.356457772651663, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3517114294293373, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0805202024778549, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3669346143017107, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9218970731127716, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.5747482927494947, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.7075180421723222, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0011616005362074, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.712327094533879, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8431413122470255, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.44965849550437276, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.737972987442064, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.335623840995829, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.24691173886388984, grad_fn=<ReluBackward>),\n",
       "       Tensor(0, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2330398625634424, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8737424952214907, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0343032249802422, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.715152507739478, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8367628645483779, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.554061316204189, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.6732087563345954, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3405934736089224, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8338141272719299, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0079167469710082, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9850887718525625, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.04449135818262673, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4090656348927952, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.4436222583801934, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.7334200493695116, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.5289976022502547, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.796558265842593, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.4947649176085219, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0872861771319138, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.5761549067455682, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.20402650193962235, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.09931502352473, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9791135534397172, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.6394789649596797, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.4443305083996202, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9838983010928859, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.96386009382318, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0835804479592888, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7408374947133133, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.6131017168364985, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7955465886086495, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9630477845335187, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.5978527830825406, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2125449877254726, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.5610499399920359, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7044563410294986, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.39113701258135, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.20139329597058098, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.498445557767019, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4429519309933998, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3794332573307226, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0080652672640107, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0458387262930382, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.29667922120870716, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8824006390255275, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7708147306354183, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.6598530137427265, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1013229345996345, grad_fn=<ReluBackward>),\n",
       "       Tensor(2.204481195238067, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4166909905714642, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.6967771762539243, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.531277288031538, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.21422968824656463, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.802940908406248, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.5092557129753206, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.5193037692193525, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9818735363821127, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8552602408159795, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.6214130736976, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4230097193910283, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.409686839202796, grad_fn=<ReluBackward>),\n",
       "       Tensor(2.2791397271149387, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7466438510144442, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8462995669500555, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.35563231662377603, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1005833561821359, grad_fn=<ReluBackward>),\n",
       "       Tensor(2.1073443753560266, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7439088594925249, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.831068839987891, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.5395457877464029, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.5759219852466702, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.6683156307534777, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7751420260597495, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2490294230772339, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.7637911774022204, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8702079875733859, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.49612820524123347, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3070545590116407, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4260290395821755, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0522185680398932, grad_fn=<ReluBackward>),\n",
       "       Tensor(0, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2637232253565176, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9902341346806951, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.7817074088054374, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.718009181002897, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.6112364962949361, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.176823245742749, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4919095285752797, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3102834658362066, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0298777318487238, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9975897591666071, grad_fn=<ReluBackward>),\n",
       "       Tensor(0, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9080784835481505, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3995700782975258, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.6087306640741021, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4633690711808494, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.5824123679606243, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2512844864480863, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3480229485998139, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.9929802905625942, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3784612558441967, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.46449511106065, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.39826758490684344, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.012347052841909845, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8055993158075783, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7809567149190471, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.38703542734047935, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9666526726041089, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9233415730265611, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4976237300868398, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.602198493953825, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.6407812626983589, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3765590727521195, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.725367519028147, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.19238645920016262, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2328766459067266, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.352025112104998, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2408431520458398, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0008724976454781, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9714217045545471, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1763624844757206, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.202942446797321, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7708529156733352, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3204753070104192, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.07336729707626888, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9065307139123036, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3886081897639078, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8758135505950752, grad_fn=<ReluBackward>),\n",
       "       Tensor(0, grad_fn=<ReluBackward>),\n",
       "       Tensor(0, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2258840162600935, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.22247833076555523, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.14448910752597588, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.18995846762243396, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2154752425281194, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0100251039182426, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.7022042803016055, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.633205765548302, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.01837108269952, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.792478147250103, grad_fn=<ReluBackward>),\n",
       "       Tensor(2.3674627589535375, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.5666116300083316, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.5449910371883537, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.48363754333747, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7313165404677016, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7836015777465526, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8537366485596274, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.6616014196474069, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.6008149218681686, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9018756685480356, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1732764469451435, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.5302510152675035, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0178797153954142, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0768968579384703, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.6219569637786098, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.7328103465171054, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.2628126950424935, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2233048293697981, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8988686259990195, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.18927156494150066, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0206025768878586, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.6653448676017657, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.241440410982692, grad_fn=<ReluBackward>),\n",
       "       Tensor(0, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.3677550770487714, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.390692641929542, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.5641325508098558, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1529706218823552, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.412925763299913, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.5723678609969616, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.6475123266193032, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.7529577522610031, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2064765632399328, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.2544642811033142, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7952925321766187, grad_fn=<ReluBackward>),\n",
       "       Tensor(0, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.19918561383644484, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.6437620274956852, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7283595542912884, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.31445366988151147, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.20643608683979997, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.8255921720853168, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7488162588924085, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.4823429766814128, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.666571300465879, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2300583568301064, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.6240804234038122, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.8293635492869162, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3623575525327176, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0615010631281032, grad_fn=<ReluBackward>),\n",
       "       Tensor(0, grad_fn=<ReluBackward>),\n",
       "       Tensor(2.017713735570021, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8807668459427176, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.4820993775076403, grad_fn=<ReluBackward>),\n",
       "       Tensor(2.271518331073966, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1812271398198977, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2344178936011794, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9188330027582419, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.5633095513672355, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.8084674555749387, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.4994042964665316, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.104579251157502, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7856307409904684, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.6111682868098589, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0475460535310972, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.4058898143623466, grad_fn=<ReluBackward>),\n",
       "       Tensor(2.624010401385772, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8416199158269232, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.6429188185696428, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8788528827624935, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3300663455354294, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.6021853651302038, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.377488290565965, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9931763153780973, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8314586801664842, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.15782183628666435, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1125943387275992, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.6164778413651584, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.7470847419970856, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.08063046300079013, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7648051464668228, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3696827124921664, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.49818992953058283, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4981199610634497, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.3523324759699169, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1725158834844616, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2240275298849932, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9204803477512221, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.6526788763669553, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9578911567738314, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.6097519249830619, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7372795133234056, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2676490234940394, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9238292068496151, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.5520148198259713, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.2296905273174138, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0651505777472159, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8535182992583311, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.5289803126469983, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.969651071173358, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1376655610297197, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2770701146455188, grad_fn=<ReluBackward>),\n",
       "       Tensor(0, grad_fn=<ReluBackward>),\n",
       "       Tensor(0, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.5756583830227555, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2629251286742391, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.5504320875492144, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.523685657179601, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.5774186687122831, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4529510547157525, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4393013618636106, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9938390777976577, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.6524141746875776, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0694251904074183, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2164182945528916, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1119658115624405, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2688691783094401, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1010520929142746, grad_fn=<ReluBackward>),\n",
       "       Tensor(2.6986413804887444, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.5293216347495129, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2699586121112663, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7870049084082216, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.19149727086280943, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4674450276469804, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.387847710906715, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7676704108609242, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9831046886730382, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.6536674714461994, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0338640101141476, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.6651486501658118, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0439565661668144, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.6110467963580588, grad_fn=<ReluBackward>),\n",
       "       Tensor(2.8311530704631442, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0451136131243661, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0870072677344158, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.086919586517267, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.84744761991032, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3031775058135753, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.25128338585651, grad_fn=<ReluBackward>),\n",
       "       Tensor(0, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2897747653447733, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.710400464364655, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.5701773466052467, grad_fn=<ReluBackward>),\n",
       "       Tensor(0, grad_fn=<ReluBackward>),\n",
       "       Tensor(2.0072816268781795, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.5914290349552304, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2102035157777191, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3226696606933148, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.4087996561889653, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.07453665220887618, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1394989149873083, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.6816513542959066, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.17590743697486433, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7635876119327047, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9571273558003066, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9273846509414261, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9199039137152264, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.8994949120592914, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.5262052855325423, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1069503968253318, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.3420120153762696, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1445281780611158, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.3775968886775882, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0672789234828832, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.322193497730754, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7531020713897119, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.05470766999920906, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7446696409645219, grad_fn=<ReluBackward>),\n",
       "       Tensor(2.1055189335636655, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.5461364539906561, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4062822864870954, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.40722772312809963, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.253126753302425, grad_fn=<ReluBackward>),\n",
       "       Tensor(2.129759911660106, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.106033662303127, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.6535221415773794, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.5728019384812424, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9446680310308989, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1746988594966588, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1671681953629198, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0174134868135203, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.64075158701488, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.4590592076517215, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.427723093556539, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4494776029977174, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1963675393986275, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.278553619894482, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8404485584644484, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.266587565363406, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9193542283509413, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2847972015963225, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.5650710239569658, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7800178345178449, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.5365083048436945, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.458805550944061, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.5900765580767642, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2403829805991242, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7907101817288376, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8872304666523613, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0464428603083797, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7287446853872739, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.40219236012991055, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.9795683795096002, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3178847710550035, grad_fn=<ReluBackward>),\n",
       "       Tensor(2.228044238402235, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.8299327574733213, grad_fn=<ReluBackward>),\n",
       "       Tensor(2.177334350369999, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7680191831098773, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9318701515561778, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9078475429101585, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.35932096620072584, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9586426660761018, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.5477872148661396, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.24958574869570704, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.27072025566029334, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.8615768375945034, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1841974851212236, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.6532521293071429, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.366145717408742, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1837218033704788, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.7758277728126937, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.897425229632111, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.8694658454642659, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9423526404193808, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0284378573460358, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1908000883529022, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.424895227675524, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1616019515851088, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1212464193180924, grad_fn=<ReluBackward>),\n",
       "       Tensor(2.822888552996945, grad_fn=<ReluBackward>),\n",
       "       Tensor(2.069802226381684, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.7805299069789797, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2932359579075396, grad_fn=<ReluBackward>),\n",
       "       Tensor(2.4521741960566987, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.6011305614548801, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3646285805455243, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.6140305648366313, grad_fn=<ReluBackward>),\n",
       "       Tensor(0, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9474449190648886, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1514738155827546, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.3889664099902308, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0475735846091543, grad_fn=<ReluBackward>),\n",
       "       Tensor(2.1459915054776846, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4324872687307209, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.15160912783242764, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.6678729348889383, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.637626592076665, grad_fn=<ReluBackward>),\n",
       "       Tensor(0, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.187680138095393, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9422607969578242, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.2959610660791725, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7073720961130254, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1209775156008603, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3045657804346884, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.5551516132671023, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.709959684972426, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.12162509114001, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8948707296716856, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7779403091355798, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.314691321875446, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4393758222787998, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4152968669272141, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9753186058345722, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1941187558893438, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4079020438758039, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4272887181828249, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2055750714067428, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8409496793784534, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4326983692684494, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4183334891327066, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7115982585491785, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2112346037184514, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2323372915634645, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9990068818870536, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.5406834904527329, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8584855572187299, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7169086596738898, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.5517645866343632, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.5404927360340621, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9745124323221052, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7638421115552341, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.49290583722742554, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8017650225104789, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.508803605980166, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3378757407261208, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.758368577577559, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.86583832727038, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.9537598804685206, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.5022530793445577, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.5967112774638341, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.03310088791940946, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3419442946812035, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8270753873044807, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7458827951357161, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0653279543395655, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.6568284260402506, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8547835553477963, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.44899174486381843, grad_fn=<ReluBackward>),\n",
       "       Tensor(0, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7659495294520318, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2299423949838884, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.46463758580047754, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.068950236411087, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7397529637262469, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.394667724876375, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1543796085712623, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.291672296627094, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.44240161123733335, grad_fn=<ReluBackward>),\n",
       "       Tensor(0, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3820809729614856, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0366624105882962, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.309419222268043, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0205726703431215, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9600425999355098, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1210308814656504, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1472166638203283, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.916040080651712, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.654636663611464, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.26649752045548036, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.9257093619360122, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4291402632041348, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.4608066050318872, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.6677018323154511, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9181025072978555, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7802983154012288, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0987926471297125, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2639461592411632, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8050150465718644, grad_fn=<ReluBackward>),\n",
       "       Tensor(0, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4133790713028214, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.5153250417776414, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0942449900609958, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8196156045530534, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0652369716016399, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.46068292174391434, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9909986381384736, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1355419255000998, grad_fn=<ReluBackward>),\n",
       "       Tensor(0, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8309884233291724, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.669344402912221, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.111885527817552, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.40891026991694157, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1542619963120826, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0603769066643907, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.011743699258326079, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9984546395885495, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0946746680160533, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2892146254433268, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.6836383409420872, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1054181891769987, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8053521790681837, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8392968796564613, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1942455637877558, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9509267850515111, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.33087760663893107, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0285949414491626, grad_fn=<ReluBackward>),\n",
       "       Tensor(0, grad_fn=<ReluBackward>),\n",
       "       Tensor(2.4442191779115765, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.236801423045182, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.6076989227408343, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.7165404522043302, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.5930130540260539, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.4730922709898914, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8184733389815249, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4780630906537164, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.6343242750431782, grad_fn=<ReluBackward>),\n",
       "       Tensor(0, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.26070976435530735, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.21299042879570695, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.708631397236958, grad_fn=<ReluBackward>),\n",
       "       Tensor(2.2838417262121746, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.7054232082190017, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.5508842906098361, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1355803854575843, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2549568912930695, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4193309255233284, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1523308067872944, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3454945921870178, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.35945564992140067, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.28840266968511086, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.233189390612227, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.5155920030020584, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7111236295307182, grad_fn=<ReluBackward>),\n",
       "       Tensor(2.1211679624330873, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.27655872777747037, grad_fn=<ReluBackward>),\n",
       "       Tensor(0, grad_fn=<ReluBackward>),\n",
       "       Tensor(0, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2920053661701298, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.7861310189348727, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8462195922735346, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.5931746030861316, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.637798265484229, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4699245139399826, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3305254222953333, grad_fn=<ReluBackward>),\n",
       "       Tensor(2.2695112329413885, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3503091552057147, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2660838365120655, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8317424647042191, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.11927741786928592, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.3920029884671855, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.5284420385583926, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.02841174306535965, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.9645093933068112, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.84182408570165, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.5112928532455228, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.6641133683095104, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1878019874724357, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3489728885620165, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1703821779140893, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3381175449652551, grad_fn=<ReluBackward>),\n",
       "       Tensor(2.3997259282158616, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3822337183904385, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.7169719553744052, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9580873151922913, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.22606210164613405, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.8346225951313362, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.557677749997818, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.6413641067360794, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.4186980346835186, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.6736933804225287, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.16071835308208593, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1131484191648007, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4977378473312193, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.857178346346635, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.6009417798844621, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.45541148653124996, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9243027950129085, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.5544841319145979, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8361045357355935, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.8032734640856778, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.907093636856166, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3409331955074903, grad_fn=<ReluBackward>),\n",
       "       Tensor(0, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.5724606728728792, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.74919196022985, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7360665169956961, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.40258138833325274, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.4109705972304515, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0150187832681474, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2771906390045245, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7293653778348324, grad_fn=<ReluBackward>),\n",
       "       Tensor(0, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.61802665199345, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.5760220480655753, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2765546189373536, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.1323303454845387, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.6504450210035613, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.441454031186973, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3849905100612043, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.5444576377429686, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7928168668960829, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.6484171073612452, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1438829369726462, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.6300588672155094, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8846098295025651, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.7814920598883979, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7493386088611951, grad_fn=<ReluBackward>),\n",
       "       Tensor(2.5313583464410243, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1347116721178976, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.828875038437085, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9761896825567103, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.3929183056277191, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8249534738133808, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8336652271698415, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.5609985343251345, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.6111058145084868, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.5335446814722067, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3200963428318375, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4540988845241327, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0649575997191332, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.08871195665239995, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.783181909731664, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0520218693808576, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.3753602535959498, grad_fn=<ReluBackward>),\n",
       "       Tensor(0, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9026002032039544, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0707127054568804, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.18941297728852202, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.6281272478902968, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.10762032079164963, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.465039520224234, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3153613156620179, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.04632710943038243, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3443547506264861, grad_fn=<ReluBackward>),\n",
       "       Tensor(0, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7520508756971277, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4732158849670423, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9476161118296129, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0108931187476247, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.8860390952859467, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.989624950663901, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.023645327936128, grad_fn=<ReluBackward>),\n",
       "       Tensor(2.193441581479057, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9949585062703508, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.6393346498210011, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9207878925554381, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8591424183042004, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8136551911259503, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8029507183220075, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.48244765675530865, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8741033792478627, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1366056599689092, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9792098640467025, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2663326859662951, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.253766534502303, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1300325132545128, grad_fn=<ReluBackward>),\n",
       "       Tensor(0, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.5005480926749382, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.582442953998132, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8263794166249083, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.811723176016668, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.7124814146023113, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1692498847802855, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0590810455850284, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.41496752515701973, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9349968025051858, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.02165234649395753, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.6172205187179223, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4594149312826215, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.486780177825639, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.065992824014035, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3307450776002896, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.579473276741943, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.652824169826331, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1374543058279283, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.094462377803883, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.888671899108291, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.7398529305696915, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.7114114509954619, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.9336354068690667, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.2848008659027793, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.5160491851989963, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7919117470065402, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.773176636616653, grad_fn=<ReluBackward>),\n",
       "       Tensor(0, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.6439197717309266, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2075448644453142, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1780036027590264, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8847552666258289, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.4198258385518412, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4468453557598573, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7970508820985696, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.3888909253836892, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9442976047810319, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.6889537599265386, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7242447897107527, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7483140630290166, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7530235744974222, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2321831150471416, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.114602971671806, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8123825487417455, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.3268526735422117, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.1942390242973585, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9845986613578918, grad_fn=<ReluBackward>),\n",
       "       Tensor(2.929524038729425, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4532135792288963, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9015974367841022, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.332942997449905, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.5939207010776455, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7027563352284522, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0164250201639256, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.8568829770194433, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.9012084320672331, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.15383866529155665, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.6579826440483546, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.8010709005981194, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.4050595225060998, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.43949585601721985, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2620014059469375, grad_fn=<ReluBackward>),\n",
       "       Tensor(0, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0207652900620823, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1318301375393722, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.5363471546561731, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3503014665786996, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1535855185572954, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.029623538021751, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.5303984874558241, grad_fn=<ReluBackward>),\n",
       "       Tensor(2.009415515671529, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.33495383109125, grad_fn=<ReluBackward>),\n",
       "       Tensor(2.219811285869927, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7055023809970299, grad_fn=<ReluBackward>),\n",
       "       Tensor(0, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.5421263030557535, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2021505916572686, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.349632925776028, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.6527018287907407, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.5470090673379833, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7884414064943834, grad_fn=<ReluBackward>),\n",
       "       Tensor(2.206022031599292, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.3639739196296655, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.1422040585217217, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3723877989047222, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9442991374943349, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.3794440051112957, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1373920749962256, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.298989754365289, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4648717723129097, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.167789743798617, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.18131255880813058, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.6167272993541166, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.197282013410376, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1772594128247564, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.8138460200703872, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0044977586796582, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.027777248650119657, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.962242928791695, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.4578170437097233, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4026163750307334, grad_fn=<ReluBackward>),\n",
       "       Tensor(0, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7244413536544256, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.4171283909790355, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.2190999158884814, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.9839456669971585, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0950596264769725, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.24193081019467133, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.1956893794269463, grad_fn=<ReluBackward>),\n",
       "       Tensor(0, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.0604636401702696, grad_fn=<ReluBackward>),\n",
       "       Tensor(1.483401354915562, grad_fn=<ReluBackward>),\n",
       "       Tensor(0.7304852128689674, grad_fn=<ReluBackward>)], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517ed13e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
