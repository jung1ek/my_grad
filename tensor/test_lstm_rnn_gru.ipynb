{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ad2c5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensor import Tensor\n",
    "from nn import Sigmoid,LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68728f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Implementation\n",
    "k = 1/4\n",
    "bound = np.sqrt(k)\n",
    "hidden_size =4\n",
    "input_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60a7dce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_wf = np.random.uniform(-bound,bound,(hidden_size,hidden_size))\n",
    "random_uf = np.random.uniform(-bound,bound,(hidden_size,input_size))\n",
    "random_bf = np.random.uniform(-bound,bound,size=(hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "643d8774",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(3,2)\n",
    "h = np.random.randn(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f5915dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.dot(random_uf,x[0]) + np.dot(random_wf,h)+random_bf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f24d4581",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbd65679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.28189369e-01, 1.90469072e+00, 5.04960786e-02, 1.85029887e-03])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f*f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a69614e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Tensor(0.4114352159642986, grad_fn=<SigmoidBackward>),\n",
       "       Tensor(0.7990079159547252, grad_fn=<SigmoidBackward>),\n",
       "       Tensor(0.4440568797887326, grad_fn=<SigmoidBackward>),\n",
       "       Tensor(0.48924788272490993, grad_fn=<SigmoidBackward>)],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(f) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "601e6207",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f27bb111",
   "metadata": {},
   "outputs": [],
   "source": [
    "output,h,s = lstm.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db7bf1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Tensor(0.8832316691201477, grad_fn=<AddBackward>),\n",
       "       Tensor(0.37598507400950737, grad_fn=<AddBackward>),\n",
       "       Tensor(0.5081084425584506, grad_fn=<AddBackward>),\n",
       "       Tensor(0.5162766265663502, grad_fn=<AddBackward>)], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9202d24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lstm.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcc1fb25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(4*4+4*2+4)*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cf0ea4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU\n",
    "from nn import GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcc7fa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru= GRU(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7810d79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output,h=gru.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096dd99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Tensor(0.5035130039846237, grad_fn=<AddBackward>),\n",
       "       Tensor(0.526806632013153, grad_fn=<AddBackward>),\n",
       "       Tensor(0.23293936475373767, grad_fn=<AddBackward>),\n",
       "       Tensor(0.40876695886780007, grad_fn=<AddBackward>)], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "163f648e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'Tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43ms\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jung__tek\\Desktop\\DL-scratch\\my_grad\\tensor\\tensor.py:111\u001b[0m, in \u001b[0;36mTensor.__sub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m    110\u001b[0m     other \u001b[38;5;241m=\u001b[39m other \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, Tensor) \u001b[38;5;28;01melse\u001b[39;00m Tensor(other)\n\u001b[1;32m--> 111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jung__tek\\Desktop\\DL-scratch\\my_grad\\tensor\\tensor.py:34\u001b[0m, in \u001b[0;36mFunction.apply\u001b[1;34m(cls, *inputs)\u001b[0m\n\u001b[0;32m     31\u001b[0m ctx \u001b[38;5;241m=\u001b[39m Context() \u001b[38;5;66;03m# iniatialize the context\u001b[39;00m\n\u001b[0;32m     33\u001b[0m inputs \u001b[38;5;241m=\u001b[39m [inp \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inp, Tensor) \u001b[38;5;28;01melse\u001b[39;00m Tensor(inp) \u001b[38;5;28;01mfor\u001b[39;00m inp \u001b[38;5;129;01min\u001b[39;00m inputs]  \u001b[38;5;66;03m# validate the *inputs (which is a and b)\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m output_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# operation; * sends arguments as tuple\u001b[39;00m\n\u001b[0;32m     37\u001b[0m output \u001b[38;5;241m=\u001b[39m Tensor(output_data) \u001b[38;5;66;03m# eg: output = f, f(a,b) = a*b\u001b[39;00m\n\u001b[0;32m     38\u001b[0m output\u001b[38;5;241m.\u001b[39mgrad_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;66;03m# Link the Function to the output Tensor\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jung__tek\\Desktop\\DL-scratch\\my_grad\\tensor\\function.py:94\u001b[0m, in \u001b[0;36mSub.forward\u001b[1;34m(ctx, a, b)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(ctx, a,b):\n\u001b[0;32m     93\u001b[0m     ctx\u001b[38;5;241m.\u001b[39msave_for_backward(a,b)\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'Tensor'"
     ]
    }
   ],
   "source": [
    "Tensor(1)-s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "694eda08",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randn(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "110fd4f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.44984457, -1.12311203,  0.27402535,  0.30952411])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66f0d1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.44984457,  2.12311203,  0.72597465,  0.69047589])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e82b2412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(0.49648699601537627, grad_fn=<SubBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor(1)-s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c733a970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Tensor(0.49648699601537627, grad_fn=<AddBackward>),\n",
       "       Tensor(0.47319336798684697, grad_fn=<AddBackward>),\n",
       "       Tensor(0.7670606352462623, grad_fn=<AddBackward>),\n",
       "       Tensor(0.5912330411322, grad_fn=<AddBackward>)], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-s+Tensor(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "daad90ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Tensor(0.5035130039846237, grad_fn=<AddBackward>),\n",
       "       Tensor(0.526806632013153, grad_fn=<AddBackward>),\n",
       "       Tensor(0.23293936475373767, grad_fn=<AddBackward>),\n",
       "       Tensor(0.40876695886780007, grad_fn=<AddBackward>)], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48c127b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Tensor(-0.4222678966583345, grad_fn=<NegBackward>),\n",
       "       Tensor(-0.4816583691124943, grad_fn=<NegBackward>),\n",
       "       Tensor(-0.4006081370934891, grad_fn=<NegBackward>),\n",
       "       Tensor(-0.5540443739887331, grad_fn=<NegBackward>)], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29578df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Tensor(0.4222678966583345, grad_fn=<AddBackward>),\n",
       "       Tensor(0.4816583691124943, grad_fn=<AddBackward>),\n",
       "       Tensor(0.4006081370934891, grad_fn=<AddBackward>),\n",
       "       Tensor(0.5540443739887331, grad_fn=<AddBackward>)], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3306e20",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a0c2806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM from scratch\n",
    "import re\n",
    "import numpy as np\n",
    "with open('../asset/the-verdict.txt','r',encoding='utf-8') as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f143f033",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = re.split(r'([,.:;?_!\"()\\']|--|\\s)',raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "853d70b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [item.strip() for item in output if item.strip()] # remove the white spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050cc67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = sorted(list(set(result)))\n",
    "all_tokens.extend([\"<|endoftext|>\",\"<|unk|>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8a7ed82",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {token:integer for integer,token in enumerate(all_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67a2f432",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "\n",
    "    def __init__(self,vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "\n",
    "    def encode(self,text:str):\n",
    "        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "    \n",
    "    def decode(self,ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])',r'\\1',text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14637d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a236da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"At Carlo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "473632c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18, 24]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c889140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [18,24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "653aee98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'At Carlo'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c667349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[988]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ed7af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unknown word and end of sentence.\n",
    "class SimpleTokenizerV2:\n",
    "\n",
    "    def __init__(self,vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "\n",
    "    def encode(self,text):\n",
    "        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        preprocessed = [item if item in self.str_to_int else \"<unk>\" for item in preprocessed]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "    \n",
    "    def decode(self,ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])',r'\\1',text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "420b398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tkr = SimpleTokenizerV2(vocab=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "caaab7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1130]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkr.encode(\"<end>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2f1b04a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<end>'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkr.decode([1130])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c629bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "451f8042",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "561ee180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15496, 995, 0]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9925595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello, do you like tea?  <|endoftext|> In the sunlit terrac\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c64ce56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15496,\n",
       " 11,\n",
       " 466,\n",
       " 345,\n",
       " 588,\n",
       " 8887,\n",
       " 30,\n",
       " 220,\n",
       " 220,\n",
       " 50256,\n",
       " 554,\n",
       " 262,\n",
       " 4252,\n",
       " 18250,\n",
       " 8812,\n",
       " 330]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(text=text,allowed_special={\"<|endoftext|>\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "011da913",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDataSetV1:\n",
    "\n",
    "    def __init__(self,txt,tokenizer,max_len,stride):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.input_ids = []\n",
    "        self.output_ids = []\n",
    "        token_ids = self.tokenizer.encode(txt)\n",
    "\n",
    "        # sliding window\n",
    "        for i in range(0,len(token_ids)-max_len,stride):\n",
    "            input_chunk = token_ids[i:i+max_len]\n",
    "            output_chunk = token_ids[i+1:i+max_len+1]\n",
    "            self.input_ids.append(input_chunk)\n",
    "            self.output_ids.append(output_chunk)\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.input_ids[idx],self.output_ids[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b18822f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GPTDataSetV1(raw_text,tokenizer,4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f28bcfd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([367, 2885, 1464, 1807], [2885, 1464, 1807, 3619])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b03d3001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding\n",
    "from nn import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d582dab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embedding = Embedding(tokenizer.n_vocab,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0549e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[Tensor(-0.03955202574128494, grad_fn=<NoneBackward>),\n",
       "        Tensor(-0.07492158717327732, grad_fn=<NoneBackward>),\n",
       "        Tensor(1.783278845366513, grad_fn=<NoneBackward>)]], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embedding([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "966dd8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# position embedding\n",
    "max_len = 256\n",
    "context_len = max_len\n",
    "embedding_layer = Embedding(context_len,embedding_size=3)\n",
    "positional_embedding = embedding_layer(np.arange(context_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d9a0ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positional_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de35c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_embedding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
