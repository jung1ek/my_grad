{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93791fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nn import MultiHeadAttention,Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d117e7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.triu(np.ones((2,4,4)),k=1).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1cf4242",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.random.randn(2,4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6661101e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# masked softmax\n",
    "masked_scores = np.where(mask,-np.inf,scores)\n",
    "# masked_scores = np_to_tensor(masked_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32376c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.32102265,        -inf,        -inf,        -inf],\n",
       "        [-1.29609073,  0.57627982,        -inf,        -inf],\n",
       "        [ 0.43666993,  0.53661296,  0.52455076,        -inf],\n",
       "        [-1.51216444, -0.70759317, -2.4941274 ,  1.6476766 ]],\n",
       "\n",
       "       [[-0.60071008,        -inf,        -inf,        -inf],\n",
       "        [-0.76468462, -1.66865086,        -inf,        -inf],\n",
       "        [ 0.28072426,  0.61694707, -1.28246518,        -inf],\n",
       "        [-0.32544925,  0.01721633, -0.12058431, -0.0762829 ]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39a862fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_scores = np.exp(masked_scores)\n",
    "scores_sm = exp_scores/np.sum(exp_scores,axis=-1,keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c832889e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.        , 0.        , 0.        , 0.        ],\n",
       "        [0.13326767, 0.86673233, 0.        , 0.        ],\n",
       "        [0.31279657, 0.34567398, 0.34152944, 0.        ],\n",
       "        [0.0367956 , 0.08226531, 0.01378272, 0.86715637]],\n",
       "\n",
       "       [[1.        , 0.        , 0.        , 0.        ],\n",
       "        [0.71176388, 0.28823612, 0.        , 0.        ],\n",
       "        [0.38327131, 0.53644602, 0.08028266, 0.        ],\n",
       "        [0.20329284, 0.28637814, 0.24951336, 0.26081566]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3af94ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.3785368 , 0.        , 0.        , 0.        ],\n",
       "        [0.27359928, 1.77940639, 0.        , 0.        ],\n",
       "        [1.54754519, 1.71020451, 1.6896996 , 0.        ],\n",
       "        [0.22043235, 0.49282893, 0.08256847, 5.19489595]],\n",
       "\n",
       "       [[0.54842207, 0.        , 0.        , 0.        ],\n",
       "        [0.46548071, 0.18850121, 0.        , 0.        ],\n",
       "        [1.32408844, 1.85326152, 0.27735273, 0.        ],\n",
       "        [0.72220283, 1.01736539, 0.88640235, 0.92655404]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87c26714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "decoder_mha = MultiHeadAttention(4,2,mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7fa70f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(6,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1efd86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[Tensor(-3.594760063820764, grad_fn=<DivBackward>)\n",
      "   Tensor(-inf, grad_fn=<NoneBackward>)\n",
      "   Tensor(-inf, grad_fn=<NoneBackward>)\n",
      "   Tensor(-inf, grad_fn=<NoneBackward>)\n",
      "   Tensor(-inf, grad_fn=<NoneBackward>)\n",
      "   Tensor(-inf, grad_fn=<NoneBackward>)]\n",
      "  [Tensor(-2.0701753840146466, grad_fn=<DivBackward>)\n",
      "   Tensor(2.470386170734479, grad_fn=<DivBackward>)\n",
      "   Tensor(-inf, grad_fn=<NoneBackward>)\n",
      "   Tensor(-inf, grad_fn=<NoneBackward>)\n",
      "   Tensor(-inf, grad_fn=<NoneBackward>)\n",
      "   Tensor(-inf, grad_fn=<NoneBackward>)]\n",
      "  [Tensor(1.7872874795944111, grad_fn=<DivBackward>)\n",
      "   Tensor(-2.0324908692594295, grad_fn=<DivBackward>)\n",
      "   Tensor(1.2830104683851236, grad_fn=<DivBackward>)\n",
      "   Tensor(-inf, grad_fn=<NoneBackward>)\n",
      "   Tensor(-inf, grad_fn=<NoneBackward>)\n",
      "   Tensor(-inf, grad_fn=<NoneBackward>)]\n",
      "  [Tensor(4.070759741517536, grad_fn=<DivBackward>)\n",
      "   Tensor(-5.39935965041701, grad_fn=<DivBackward>)\n",
      "   Tensor(3.606375037333029, grad_fn=<DivBackward>)\n",
      "   Tensor(2.9817735689259575, grad_fn=<DivBackward>)\n",
      "   Tensor(-inf, grad_fn=<NoneBackward>)\n",
      "   Tensor(-inf, grad_fn=<NoneBackward>)]\n",
      "  [Tensor(-0.3956959914086437, grad_fn=<DivBackward>)\n",
      "   Tensor(1.3440689818621874, grad_fn=<DivBackward>)\n",
      "   Tensor(-1.0783481016323075, grad_fn=<DivBackward>)\n",
      "   Tensor(-0.31865239886288305, grad_fn=<DivBackward>)\n",
      "   Tensor(-1.2865388342602726, grad_fn=<DivBackward>)\n",
      "   Tensor(-inf, grad_fn=<NoneBackward>)]\n",
      "  [Tensor(-1.3425243955561093, grad_fn=<DivBackward>)\n",
      "   Tensor(2.787110289535169, grad_fn=<DivBackward>)\n",
      "   Tensor(-2.0834620200945086, grad_fn=<DivBackward>)\n",
      "   Tensor(-1.0187738733338467, grad_fn=<DivBackward>)\n",
      "   Tensor(-2.5114770400451962, grad_fn=<DivBackward>)\n",
      "   Tensor(-3.2820011951954626, grad_fn=<DivBackward>)]]\n",
      "\n",
      " [[Tensor(-1.9069554819114298, grad_fn=<DivBackward>)\n",
      "   Tensor(-inf, grad_fn=<NoneBackward>)\n",
      "   Tensor(-inf, grad_fn=<NoneBackward>)\n",
      "   Tensor(-inf, grad_fn=<NoneBackward>)\n",
      "   Tensor(-inf, grad_fn=<NoneBackward>)\n",
      "   Tensor(-inf, grad_fn=<NoneBackward>)]\n",
      "  [Tensor(1.2668284272632186, grad_fn=<DivBackward>)\n",
      "   Tensor(-0.3314930964025868, grad_fn=<DivBackward>)\n",
      "   Tensor(-inf, grad_fn=<NoneBackward>)\n",
      "   Tensor(-inf, grad_fn=<NoneBackward>)\n",
      "   Tensor(-inf, grad_fn=<NoneBackward>)\n",
      "   Tensor(-inf, grad_fn=<NoneBackward>)]\n",
      "  [Tensor(-1.006290960276969, grad_fn=<DivBackward>)\n",
      "   Tensor(-0.021705012354778067, grad_fn=<DivBackward>)\n",
      "   Tensor(0.1212639807831931, grad_fn=<DivBackward>)\n",
      "   Tensor(-inf, grad_fn=<NoneBackward>)\n",
      "   Tensor(-inf, grad_fn=<NoneBackward>)\n",
      "   Tensor(-inf, grad_fn=<NoneBackward>)]\n",
      "  [Tensor(-5.366014374122872, grad_fn=<DivBackward>)\n",
      "   Tensor(0.46556473807788107, grad_fn=<DivBackward>)\n",
      "   Tensor(0.6492733284088179, grad_fn=<DivBackward>)\n",
      "   Tensor(0.9573455664837994, grad_fn=<DivBackward>)\n",
      "   Tensor(-inf, grad_fn=<NoneBackward>)\n",
      "   Tensor(-inf, grad_fn=<NoneBackward>)]\n",
      "  [Tensor(-0.4193776784463052, grad_fn=<DivBackward>)\n",
      "   Tensor(0.6832238228607703, grad_fn=<DivBackward>)\n",
      "   Tensor(0.05367787830719308, grad_fn=<DivBackward>)\n",
      "   Tensor(0.3465660057652026, grad_fn=<DivBackward>)\n",
      "   Tensor(0.15504230660377652, grad_fn=<DivBackward>)\n",
      "   Tensor(-inf, grad_fn=<NoneBackward>)]\n",
      "  [Tensor(-1.827237842201382, grad_fn=<DivBackward>)\n",
      "   Tensor(2.0484194787840493, grad_fn=<DivBackward>)\n",
      "   Tensor(0.22966411776646775, grad_fn=<DivBackward>)\n",
      "   Tensor(1.1199617556180703, grad_fn=<DivBackward>)\n",
      "   Tensor(0.34029179320962805, grad_fn=<DivBackward>)\n",
      "   Tensor(-2.5607226674225703, grad_fn=<DivBackward>)]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[Tensor(9.6990377657093, grad_fn=<AddBackward>),\n",
       "        Tensor(1.0509971543400365, grad_fn=<AddBackward>),\n",
       "        Tensor(1.0960242223439352, grad_fn=<AddBackward>),\n",
       "        Tensor(7.01108541195989, grad_fn=<AddBackward>)],\n",
       "       [Tensor(0.6352129967910511, grad_fn=<AddBackward>),\n",
       "        Tensor(5.469397956723299, grad_fn=<AddBackward>),\n",
       "        Tensor(7.619279938180826, grad_fn=<AddBackward>),\n",
       "        Tensor(2.070880781803244, grad_fn=<AddBackward>)],\n",
       "       [Tensor(3.97102074244293, grad_fn=<AddBackward>),\n",
       "        Tensor(-3.480563541419489, grad_fn=<AddBackward>),\n",
       "        Tensor(-0.5216194490724876, grad_fn=<AddBackward>),\n",
       "        Tensor(3.221859088241157, grad_fn=<AddBackward>)],\n",
       "       [Tensor(3.1288355539247235, grad_fn=<AddBackward>),\n",
       "        Tensor(-3.0139615108611166, grad_fn=<AddBackward>),\n",
       "        Tensor(-1.8392521042237067, grad_fn=<AddBackward>),\n",
       "        Tensor(2.121928643938757, grad_fn=<AddBackward>)],\n",
       "       [Tensor(-0.6152546726178196, grad_fn=<AddBackward>),\n",
       "        Tensor(-0.13224781715336398, grad_fn=<AddBackward>),\n",
       "        Tensor(3.3848545808102464, grad_fn=<AddBackward>),\n",
       "        Tensor(0.6215469158012737, grad_fn=<AddBackward>)],\n",
       "       [Tensor(-1.4819498191301483, grad_fn=<AddBackward>),\n",
       "        Tensor(-0.5658855337098267, grad_fn=<AddBackward>),\n",
       "        Tensor(5.149372866429377, grad_fn=<AddBackward>),\n",
       "        Tensor(1.2128297651447846, grad_fn=<AddBackward>)]], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_mha(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50881777",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7651e6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09339752, 0.23805229, 0.52417333, 0.14437686],\n",
       "       [0.04920652, 0.53397228, 0.11097922, 0.30584198],\n",
       "       [0.23755683, 0.12931227, 0.3262771 , 0.3068538 ],\n",
       "       [0.35153752, 0.19493892, 0.32379323, 0.12973033]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(x)/np.sum(np.exp(x),axis=-1,keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "499ded7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder layer\n",
    "from nn import MultiHeadAttention, LayerNorm, Softmax,Relu,LinearLayer,TransformerDecoderLayer,PositionalEcnoding,Embedding\n",
    "from tensor import Tensor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e22db49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "td= TransformerDecoderLayer(3,4,10,10,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "274788a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randint(0,10,3)\n",
    "q = np.random.randn(3,4)\n",
    "k = np.random.randn(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b96af73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 5, 6])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88bbe77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Tensor(0.4277948944569567, grad_fn=<ReluBackward>),\n",
       "  Tensor(0, grad_fn=<ReluBackward>),\n",
       "  Tensor(0.039597083924540206, grad_fn=<ReluBackward>),\n",
       "  Tensor(1.1275812310939748, grad_fn=<ReluBackward>)],\n",
       " [Tensor(1.1493073866768604, grad_fn=<ReluBackward>),\n",
       "  Tensor(0, grad_fn=<ReluBackward>),\n",
       "  Tensor(0, grad_fn=<ReluBackward>),\n",
       "  Tensor(0.81259109607819, grad_fn=<ReluBackward>)],\n",
       " [Tensor(0, grad_fn=<ReluBackward>),\n",
       "  Tensor(0, grad_fn=<ReluBackward>),\n",
       "  Tensor(0.6546298739672148, grad_fn=<ReluBackward>),\n",
       "  Tensor(1.088147924939086, grad_fn=<ReluBackward>)]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td(q,k,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6330e6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ie = Embedding(10,4)\n",
    "pe = PositionalEcnoding(3,4)\n",
    "mha = MultiHeadAttention(4,2)\n",
    "ln = LayerNorm(4)\n",
    "mask_mha = MultiHeadAttention(4,2,mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e95a0c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randint(0,10,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab311f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = ie(x)\n",
    "out = out + pe()\n",
    "out = ln(out+mask_mha(out,out,out))\n",
    "out = np.array(out) # layernorm return list so,\n",
    "out = ln(out+ mha(out,out,out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f57cc64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Tensor(0, grad_fn=<ReluBackward>),\n",
       "  Tensor(0.3526634059732605, grad_fn=<ReluBackward>),\n",
       "  Tensor(0, grad_fn=<ReluBackward>),\n",
       "  Tensor(1.416311507296194, grad_fn=<ReluBackward>)],\n",
       " [Tensor(0, grad_fn=<ReluBackward>),\n",
       "  Tensor(0.29857490111460444, grad_fn=<ReluBackward>),\n",
       "  Tensor(0, grad_fn=<ReluBackward>),\n",
       "  Tensor(1.4927553224150554, grad_fn=<ReluBackward>)],\n",
       " [Tensor(0, grad_fn=<ReluBackward>),\n",
       "  Tensor(0.7242165665555933, grad_fn=<ReluBackward>),\n",
       "  Tensor(0, grad_fn=<ReluBackward>),\n",
       "  Tensor(1.2259731625781805, grad_fn=<ReluBackward>)]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505e5a01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
