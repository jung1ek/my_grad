{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52f4b938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c457fed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10499358540350662"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking grad, direct sigmoid function and manual op sigmoid  funciton\n",
    "# direct sigmoid function\n",
    "\n",
    "x = Tensor(2.0)\n",
    "y = x.sigmoid()\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06122ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1049935854035065"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manual sigmoid\n",
    "x_1 = Tensor(2.0)\n",
    "y_1 = Tensor(1.0)/(Tensor(1.0)+((-x_1).exp()))\n",
    "y_1.backward()\n",
    "x_1.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f96dfc76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the averageing the loss and manual averaging the grad\n",
    "# manual grad\n",
    "w = Tensor(2.0)\n",
    "x = [Tensor(2.0),Tensor(3.0)]\n",
    "y = [Tensor(1.0),Tensor(2.0)]\n",
    "loss = [((w*xi)-yi)**2 for xi,yi in zip(x,y)]\n",
    "loss[1].backward()\n",
    "loss[0].backward()\n",
    "w.grad/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab12e25d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# averaging the loss grad\n",
    "w = Tensor(2.0)\n",
    "x = [Tensor(2.0),Tensor(3.0)]\n",
    "y = [Tensor(1.0),Tensor(2.0)]\n",
    "loss = [((w*xi)-yi)**2 for xi,yi in zip(x,y)]\n",
    "avg_loss = (loss[0]+loss[1])/2\n",
    "avg_loss.backward()\n",
    "w.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5b2205",
   "metadata": {},
   "source": [
    "Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0fe7c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn import Softmax\n",
    "import numpy as np\n",
    "from tensor import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36191436",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(101)\n",
    "np_to_tensor = np.vectorize(lambda x: Tensor(x))\n",
    "x = np.random.randn(5)\n",
    "a = np_to_tensor(x)\n",
    "x = np_to_tensor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dbadb5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tensor(0.6540041214179446, grad_fn=<SoftmaxBackward>),\n",
       " Tensor(0.08180975761030067, grad_fn=<SoftmaxBackward>),\n",
       " Tensor(0.1082272583598544, grad_fn=<SoftmaxBackward>),\n",
       " Tensor(0.07224691070875887, grad_fn=<SoftmaxBackward>),\n",
       " Tensor(0.08371195190314144, grad_fn=<SoftmaxBackward>)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nn Softmax\n",
    "sf  = Softmax()\n",
    "o = sf(x)\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bb7761ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "o[-1].backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cd18ef72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.054747961556595254\n",
      "-0.006848454494281149\n",
      "-0.009059915046428994\n",
      "-0.006047929914402177\n",
      "0.07670426101170758\n"
     ]
    }
   ],
   "source": [
    "for xi in x:\n",
    "    print(xi.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9ee4e96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Tensor(0.6540041214179446, grad_fn=<DivBackward>),\n",
       "       Tensor(0.08180975761030067, grad_fn=<DivBackward>),\n",
       "       Tensor(0.1082272583598544, grad_fn=<DivBackward>),\n",
       "       Tensor(0.07224691070875887, grad_fn=<DivBackward>),\n",
       "       Tensor(0.08371195190314144, grad_fn=<DivBackward>)], dtype=object)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manual Softmax\n",
    "o_1 = np.exp(a)/np.sum(np.exp(a),axis=-1,keepdims=True)\n",
    "o_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bf092a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "o_1[-1].backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "051a65c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.054747961556595254\n",
      "-0.006848454494281149\n",
      "-0.009059915046428994\n",
      "-0.006047929914402177\n",
      "0.07670426101170758\n"
     ]
    }
   ],
   "source": [
    "for xi in x:\n",
    "    print(xi.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6e59778c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# grad of all variable\n",
    "for xi in x:\n",
    "    xi.backward()\n",
    "\n",
    "for xi in x:\n",
    "    print(xi.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "25c54e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for ai in a:\n",
    "    ai.backward()\n",
    "\n",
    "for ai in a:\n",
    "    print(ai.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf316d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50c58923",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(101)\n",
    "z = torch.randn(5,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "489a117f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.3905, -0.8152, -0.3204,  0.7377, -1.7534], requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e81022e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sft = torch.nn.Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15e9edfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0676, 0.1202, 0.1971, 0.5680, 0.0470], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jung__tek\\AppData\\Local\\Temp\\ipykernel_4000\\744034382.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  o_2 = sft(z)\n"
     ]
    }
   ],
   "source": [
    "o_2 = sft(z)\n",
    "print(o_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f581ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0081,  0.1058, -0.0237, -0.0683, -0.0057])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_2[1].backward()\n",
    "z.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c83446e",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = [Tensor(-1.3905), Tensor(-0.8152), Tensor(-0.3204),  Tensor(0.7377), Tensor(-1.7534)]\n",
    "o3 = sf(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4311c9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.008128083943991338\n",
      "0.1057549937586445\n",
      "-0.023698819067821158\n",
      "-0.06827374041828776\n",
      "-0.0056543503285442385\n"
     ]
    }
   ],
   "source": [
    "o3[1].backward()\n",
    "for zi in z:\n",
    "    print(zi.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380417e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
